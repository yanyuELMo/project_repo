{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Accident Detection MLOps","text":"<p>End-to-end MLOps pipeline for road traffic accident detection (videos \u2192 model \u2192 API \u2192 monitoring).</p>"},{"location":"#whats-inside","title":"What\u2019s inside","text":"<ul> <li>Data versioned with DVC (GCS remote); manifests under <code>data/</code>.</li> <li>Configured training with Hydra + Typer CLI; profiling hooks; logging to Weights &amp; Biases.</li> <li>FastAPI inference service (Prometheus metrics); Streamlit frontend.</li> <li>CI on GitHub Actions (lint/format/tests/coverage); data/registry triggers.</li> <li>Containers built via Cloud Build and published to Container/Artifact Registry; deployed on Cloud Run.</li> <li>Monitoring via Managed Prometheus; drift detection API with Evidently; load testing with k6/Locust.</li> </ul>"},{"location":"#quick-start-local","title":"Quick start (local)","text":"<ul> <li>Install deps: <code>pip install -r .devcontainer/requirements.txt</code></li> <li>Pull data (DVC, GCS default): <code>dvc pull</code></li> <li>CLI (Typer/Hydra):</li> <li>Preprocess/train/report: <code>python -m src.cli preprocess|train|report [overrides]</code></li> <li>Profiling example: <code>python -m src.cli train train.profile_steps=10 train.profile_only=true</code></li> <li>Tests: <code>pytest -q</code></li> <li>API (FastAPI): <code>uvicorn src.api:app --host 0.0.0.0 --port 8000</code></li> <li>Pre-commit: <code>pre-commit run --all-files</code></li> <li>W&amp;B: set <code>WANDB_API_KEY</code> (optional <code>wandb.project/entity/run_name/tags</code>); disable with <code>wandb.enabled=false</code>.</li> </ul>"},{"location":"#docs-map","title":"Docs map","text":"<ul> <li>Pipeline: diagram + flow.</li> <li>Usage: data, training, API, quantization, load testing.</li> <li>Deployment &amp; Ops: CI/CD, Cloud Build/Run, monitoring, drift, frontend.</li> </ul>"},{"location":"deployment/","title":"Deployment &amp; Ops","text":""},{"location":"deployment/#cicd","title":"CI/CD","text":"<ul> <li>GitHub Actions: lint/format/tests/coverage (pre-commit, ruff, isort, mypy, pytest).</li> <li>Additional triggers for data and registry changes.</li> <li>Cloud Build Trigger kicks off image builds on main.</li> </ul>"},{"location":"deployment/#cloud-build-registry","title":"Cloud Build &amp; Registry","text":"<ul> <li>Config: <code>cloudbuild.yaml</code> builds the FastAPI image.</li> <li>Output: image pushed to Container/Artifact Registry.</li> </ul>"},{"location":"deployment/#cloud-run-inference","title":"Cloud Run (inference)","text":"<ul> <li>Deploy image to Cloud Run. Example:   <code>bash   gcloud run deploy accident-api \\     --project=&lt;project&gt; --region=&lt;region&gt; --platform=managed \\     --image=&lt;region&gt;-docker.pkg.dev/&lt;project&gt;/mlops02476-accident-images-eu-7f3a/app:latest \\     --port=8000 --cpu=1 --memory=1Gi --allow-unauthenticated \\     --set-env-vars=MODEL_CHECKPOINT=gs://&lt;bucket&gt;/weights/best.pt,THRESHOLD=0.5</code></li> <li>Cloud Run pulls the container from Registry and the checkpoint from GCS.</li> </ul>"},{"location":"deployment/#monitoring","title":"Monitoring","text":"<ul> <li>FastAPI exposes Prometheus metrics (<code>/metrics</code> counters + latency histograms).</li> <li>Managed Prometheus scrapes via Cloud Run sidecar (see <code>deploy/api/cloudrun-gmp-sidecar.yaml</code> in repo).</li> <li>Use Metrics Explorer/PromQL for latency, errors, and request volume.</li> </ul>"},{"location":"deployment/#drift-detection","title":"Drift detection","text":"<ul> <li>Build baseline: <code>python scripts/build_baseline_features.py --input-dir data/processed/clips --output baseline.csv --limit 500</code></li> <li>Drift report: <code>python scripts/drift_report.py --reference baseline.csv --current current.csv --out-html artifacts/evidently_drift_report.html --out-json artifacts/evidently_drift_report.json</code></li> <li>Drift API: <code>deploy/monitoring/app.py</code>; deploy to Cloud Run (<code>BASELINE_CSV</code>, <code>LOG_BUCKET</code>, <code>CURRENT_LIMIT</code> envs).</li> </ul>"},{"location":"deployment/#frontend-load","title":"Frontend &amp; load","text":"<ul> <li>Streamlit frontend (<code>deploy/frontend/frontend.py</code>) calls the Cloud Run API; Dockerfile available under <code>deploy/frontend/</code>.</li> <li>Load testing via k6 (<code>deploy/loadtest.js</code>) and Locust (<code>deploy/locustfile.py</code>).</li> </ul>"},{"location":"pipeline/","title":"Pipeline","text":""},{"location":"pipeline/#flow-overview","title":"Flow overview","text":"<p>1) Local dev (containerized): work in Docker/devcontainer; pull data from GCS via DVC; run Typer/Hydra CLI for preprocess/train; log metrics/artifacts and sweeps to W&amp;B; produce checkpoints/ONNX with optional quantization/pruning; smoke-test the API image locally with Docker. 2) GitHub/CI: push to GitHub; GitHub Actions runs lint/format/tests/coverage (pre-commit, ruff, isort, mypy, pytest) and caches deps; data/registry change triggers are wired in CI. 3) GCP build &amp; deploy: Cloud Build Trigger \u2192 Cloud Build \u2192 Container Registry; Cloud Run pulls the image and the model checkpoint from GCS via env vars. 4) Serving &amp; monitoring: Cloud Run inference API (FastAPI) exports metrics to Managed Prometheus; logs/inputs land in GCS; Evidently drift detection service (Cloud Run) reads baseline/current from GCS. 5) Clients: Streamlit frontend, load testing (k6/Locust), and end users send HTTPS requests to Cloud Run.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#data-configs","title":"Data &amp; configs","text":"<ul> <li>Data is DVC-tracked (GCS remote). Pull: <code>dvc pull</code>. Switch remote with <code>dvc remote default gcs|local</code>.</li> <li>Hydra configs under <code>configs/</code> (e.g., <code>configs/train/train.yaml</code>). Override via CLI flags: <code>python -m src.cli train train.batch_size=32 data.train_path=...</code>.</li> </ul>"},{"location":"usage/#training","title":"Training","text":"<ul> <li>Entry: <code>python -m src.cli train [overrides]</code>.</li> <li>Profiling: <code>python -m src.cli train train.profile_steps=10 train.profile_only=true</code>.</li> <li>W&amp;B logging enabled by default; set <code>WANDB_API_KEY</code> and optional project/entity/run_name/tags.</li> </ul>"},{"location":"usage/#inference-api-local","title":"Inference API (local)","text":"<ul> <li>Run FastAPI: <code>uvicorn src.api:app --host 0.0.0.0 --port 8000</code></li> <li>Request example: upload <code>.npz</code> with <code>frames</code> shaped <code>[T,H,W,3]</code> (uint8) to <code>/predict</code>.</li> <li>Env vars: <code>MODEL_CHECKPOINT</code> (optional GCS path), <code>MODEL_NAME</code>, <code>K_FRAMES</code>, <code>THRESHOLD</code>.</li> </ul>"},{"location":"usage/#model-speedups","title":"Model speedups","text":"<ul> <li>Quantize ONNX \u2192 INT8:   <code>bash   python scripts/quantize_onnx.py \\     --input artifacts/checkpoints/best.onnx \\     --output artifacts/checkpoints/best-int8.onnx</code></li> <li>Other options mentioned: <code>torch.compile</code>, pruning, TensorRT/ORT execution providers (not fully scripted).</li> </ul>"},{"location":"usage/#load-testing","title":"Load testing","text":"<ul> <li>k6: <code>APP_URL=https://&lt;service&gt;/predict NPZ_PATH=dummy.npz k6 run deploy/loadtest.js</code></li> <li>Locust: <code>APP_PATH=/predict NPZ_PATH=dummy.npz locust -f deploy/locustfile.py --host https://&lt;service&gt; --web-host 0.0.0.0 --web-port 8089</code></li> </ul>"}]}